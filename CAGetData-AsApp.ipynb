{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d591e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from osmapi import OsmApi\n",
    "MyApi = OsmApi()\n",
    "import pyproj\n",
    "#import polars as pl\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "geodesic = pyproj.Geod(ellps='WGS84')\n",
    "\n",
    "selected_cols = ['data.id','data.timestamp','data.user','data.uid','data.tag.railway','data.tag.highway','data.tag.service','data.tag.tiger:county','data.tag.name','data.tag.electrified','data.tag.gauge','data.tag.operator','data.tag.owner','data.tag.railway:preserved','data.tag.usage','data.tag.maxspeed','prev_node','prev_node_lat','prev_node_lon','fwd_azimuth_to_crossing','back_azimuth_to_crossing','distance_to_crossing','related__OSM_Node','related__OSM_Node_lat','related__OSM_Node_lon','realted_FRA_ID','data.tag.access','data.tag.surface','data.tag.bicycle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afe38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast Date Column of InventoryDf\n",
    "inventoryDf = pd.read_excel('Crossing_CA.xlsx')\n",
    "inventoryDf['revisiondate'] = pd.to_datetime(inventoryDf['revisiondate'])\n",
    "\n",
    "#Sort and Drop duplicates\n",
    "\n",
    "\n",
    "inventoryDf = inventoryDf.sort_values('revisiondate').drop_duplicates('crossingid',keep='last')\n",
    "#df.sort_values('DATE_CHANGED').drop_duplicates('STATION_ID',keep='last')\n",
    "inventoryDf = inventoryDf[inventoryDf['latitude'].notnull()]\n",
    "\n",
    "inventoryDf = inventoryDf[inventoryDf['longitude'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ba5615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81861b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "\n",
    "def flatten_dict(d: MutableMapping, sep: str= '.') -> MutableMapping:\n",
    "    [flat_dict] = pd.json_normalize(d, sep=sep).to_dict(orient='records')\n",
    "    return flat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f39080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  FRA:  751386X\n",
      "False\n",
      "something went wrong with : 455 751386X \"['poop', 'data.tag.service', 'data.tag.maxspeed', 'data.tag.access', 'data.tag.surface'] not in index\"\n",
      "1  FRA:  857915A\n",
      "False\n",
      "something went wrong with : 454 857915A \"['poop', 'data.tag.railway:preserved', 'data.tag.bicycle'] not in index\"\n",
      "2  FRA:  498838K\n",
      "search area increased to  0.002\n",
      "search area increased to  0.004\n",
      "search area increased to  0.008\n",
      "still missing crossing\n",
      "3  FRA:  751443J\n",
      "False\n",
      "something went wrong with : 452 751443J \"['poop', 'data.tag.service', 'data.tag.maxspeed', 'data.tag.surface'] not in index\"\n",
      "4  FRA:  749386X\n",
      "search area increased to  0.002\n",
      "search area increased to  0.004\n",
      "search area increased to  0.008\n",
      "still missing crossing\n",
      "5  FRA:  498982C\n",
      "search area increased to  0.002\n",
      "search area increased to  0.004\n",
      "search area increased to  0.008\n",
      "still missing rail\n",
      "6  FRA:  847372J\n",
      "False\n",
      "something went wrong with : 448 847372J \"['poop', 'data.tag.service', 'data.tag.electrified', 'data.tag.gauge', 'data.tag.owner', 'data.tag.railway:preserved', 'data.tag.usage', 'data.tag.maxspeed', 'data.tag.access'] not in index\"\n",
      "7  FRA:  837843U\n",
      "search area increased to  0.002\n",
      "False\n",
      "something went wrong with : 446 837843U \"['poop', 'data.tag.railway:preserved', 'data.tag.access', 'data.tag.surface'] not in index\"\n",
      "8  FRA:  768202W\n",
      "False\n",
      "something went wrong with : 444 768202W \"['poop', 'data.tag.service', 'data.tag.railway:preserved'] not in index\"\n"
     ]
    }
   ],
   "source": [
    "allRows = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i, row in inventoryDf.iloc[1:10].iterrows():\n",
    "    \n",
    "    print(count, ' FRA: ', row['crossingid'])\n",
    "    count = count + 1\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        fra_crossing_id = row['crossingid']\n",
    "        fra_lat = row['latitude']\n",
    "        fra_lon = row['longitude']\n",
    "        \n",
    "        \n",
    "\n",
    "        search_level = 0.001\n",
    "        max_search_level = 0.005\n",
    "        \n",
    "        results_dict = MyApi.Map(fra_lon-search_level,fra_lat-search_level,fra_lon+search_level,fra_lat+search_level)\n",
    "        \n",
    "        flat_dict = []\n",
    "        for d in results_dict:\n",
    "            flat_dict.append(flatten_dict(d))\n",
    "\n",
    "        df = pd.DataFrame.from_dict(flat_dict)\n",
    "        \n",
    "        crossings_df = pd.DataFrame()\n",
    "        \n",
    "        if('data.tag.railway' in df.columns):\n",
    "            crossings_df= df[df['data.tag.railway'] == 'level_crossing']\n",
    "         \n",
    "        \n",
    "        while search_level < max_search_level and crossings_df.shape[0] <= 0:\n",
    "            search_level = search_level* 2\n",
    "            print('search area increased to ', search_level)\n",
    "            results_dict = MyApi.Map(fra_lon-search_level,fra_lat-search_level,fra_lon+search_level,fra_lat+search_level)\n",
    "        \n",
    "            flat_dict = []\n",
    "            for d in results_dict:\n",
    "                flat_dict.append(flatten_dict(d))\n",
    "\n",
    "            df = pd.DataFrame.from_dict(flat_dict)\n",
    "            \n",
    "            if('data.tag.railway' in df.columns):\n",
    "                crossings_df= df[df['data.tag.railway'] == 'level_crossing']\n",
    "            \n",
    "            \n",
    "        if('data.tag.railway' not in df.columns):\n",
    "            print(\"still missing rail\")\n",
    "            continue\n",
    "        \n",
    "        if(crossings_df.shape[0] <= 0):\n",
    "            print(\"still missing crossing\")\n",
    "            continue\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        crossings_df['customdistance']= crossings_df.apply(lambda g: geodesic.inv(fra_lon, fra_lat, g['data.lon'], g['data.lat'])[2],axis=1)\n",
    "        crossings_df = crossings_df.sort_values(by=['customdistance'])\n",
    "\n",
    "        crossing_node = crossings_df.iloc[0]['data.id']\n",
    "\n",
    "        osm_crossing_lat = crossings_df.iloc[0]['data.lat']\n",
    "        osm_crossing_lon = crossings_df.iloc[0]['data.lon']\n",
    "\n",
    "        ways = df[df['data.nd'].notnull()]\n",
    "        inWays = ways[ways['data.nd'].apply(lambda x: crossing_node in x)]\n",
    "\n",
    "\n",
    "        inWays['prev_node'] = inWays['data.nd'].apply(lambda x: x[x.index(crossing_node)-1])\n",
    "\n",
    "        #get data on the previous way\n",
    "        inWays['prev_node_lat'] = inWays.apply(lambda x: MyApi.NodeGet(x['prev_node'])['lat'],axis=1)\n",
    "        inWays['prev_node_lon'] = inWays.apply(lambda x: MyApi.NodeGet(x['prev_node'])['lon'],axis=1)\n",
    "\n",
    "\n",
    "        inWays['fwd_azimuth_to_crossing']= inWays.apply(lambda g: geodesic.inv(osm_crossing_lon, osm_crossing_lat, g['prev_node_lon'], g['prev_node_lat'])[0],axis=1)\n",
    "        inWays['back_azimuth_to_crossing']= inWays.apply(lambda g: geodesic.inv(osm_crossing_lon, osm_crossing_lat, g['prev_node_lon'], g['prev_node_lat'])[1],axis=1)\n",
    "        inWays['distance_to_crossing']= inWays.apply(lambda g: geodesic.inv(osm_crossing_lon, osm_crossing_lat, g['prev_node_lon'], g['prev_node_lat'])[2],axis=1)\n",
    "\n",
    "        inWays = inWays.assign(related__OSM_Node=crossing_node)\n",
    "\n",
    "\n",
    "        inWays = inWays.assign(related__OSM_Node_lat=osm_crossing_lat)\n",
    "        inWays = inWays.assign(related__OSM_Node_lon=osm_crossing_lon)\n",
    "\n",
    "        inWays = inWays.assign(realted_FRA_ID=fra_crossing_id)\n",
    "        \n",
    "            \n",
    "        \n",
    "        for iS, rowS in inWays.iterrows():\n",
    "            allRows.append(rowS.to_dict())\n",
    "        \n",
    "           # print(inWays.to_dict())\n",
    "        \n",
    "        #every 1000 lets update the csv\n",
    "        if count % 1000 == 0:\n",
    "            print(\"Update CSV \", count)\n",
    "            df = pd.DataFrame(allRows)\n",
    "            \n",
    "\n",
    "            \n",
    "    except Exception  as e:\n",
    "        print('something went wrong with :' , i,row['crossingid'], e)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "df = pd.DataFrame(allRows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  \n",
    "\n",
    "time_stamp = time.time()\n",
    "\n",
    "file_name = 'CA_AZ_DATA_thread_2' + str(time_stamp) + '.csv'\n",
    "\n",
    "df.to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
